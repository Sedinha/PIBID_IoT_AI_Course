Ae! Salve pessoa linda! Seja bem-vinda ao curso Introdução à Internet das Coisas. Eu sou professora, Rafaela. Sou formado em Ciência da Computação, doutora em Engenharia e Gestão do Conhecimento e eu trabalho há bastante tempo com tecnologias para facilitar a vida de pessoas como você, que está assistindo a esse vídeo. E nesse vídeo nós vamos trazer alguns pontos de reflexão sobre a ética e a internet das coisas. Se interessou? Então fica ligado! Roda a vinheta! Bom, já vou te avisar logo de cara que esse não é um vídeo que traz respostas e vai trazer muito mais perguntas para que a gente possa refletir um pouco sobre a questão da ética e da internet das coisas. É uma pequena provocação, pois é um assunto bem complexo tratar de ética e moralidade. Já sabemos que a Internet das Coisas permite que fazer interação de sistemas com um ambiente por meio de sensores e controladores. Dessa forma, é possível afirmar que as coisas através da internet, das coisas e dos seus protocolos podem ser capazes de se interconectar de um certo modo, até ter inteligência. Os sensores podem coletar informações nossas o tempo todo. É o primeiro ponto de reflexão que eu quero trazer aqui. É que, a partir da década de 1980, com o desenvolvimento da informática nas empresas e na administração pública, houve a percepção de que as práticas governamentais e corporativas, quando se tratava de dados pessoais, estava reduzindo os indivíduos a meros dados, ameaçando os direitos fundamentais à sua liberdade. Inclusive, teve uma época que as empresas compravam e vendiam os dados dos usuários sem nem avisar, e a gente nem sabia, na verdade, que eles estavam guardando os dados. Agora a gente já sabe o que é um cookies e pode escolher o que compartilhar. Será? Eu confesso que na maior parte do tempo eu sou meio kamikaze, só vou aceitando tudo. Mas voltando, como assim ter os direitos fundamentais de liberdade ameaçado por causa dos dados? Ora, pois para alguns pensadores humanistas como Rousseau, os nossos sentimentos e desejos foram a fonte última de significado e o nosso livre arbítrio era, portanto, a mais alta autoridade de todas na questão de decisão. Na visão humanista, nós temos as nossas próprias escolhas baseadas nos nossos sentimentos e emoções. E agora está ocorrendo uma mudança de visão, onde os gurus de alta tecnologia e os profetas do Vale do Silício estão criando uma nova narrativa universal que legitima a autoridade dos algoritmos e do big data . Isso da mesma forma que aconteceu com autoridades divinas, que foram legitimadas por mitologias e religiões, e a autoridade humana, que foi legitimada por ideologias humanistas. Tanto que quem trabalha com vendas e marketing, por exemplo, está o tempo todo ligado nas mudanças do tal algoritmo das redes sociais. O algoritmo se tornou uma entidade e é comum você escutar frases como o algoritmo não está entregando o meu conteúdo, preciso publicar mais vídeo porque agora é isso que o algoritmo entrega e prioriza e por aí vai. Essa nova visão de mundo acabou ganhando o nome, o Dataísmo. Esse termo foi utilizado pela primeira vez por David Brooks, um jornalista do New York Times, em 2013, onde ele argumentou que, num mundo crescentemente complexo, confiar nos dados pode reduzir as distorções cognitivas e eliminar padrões de comportamento que a gente ainda não tinha observado, não tinha pensado. Se a gente pensar dessa forma, teríamos um mundo repleto de decisões lógicas. Mas existem outros fatores que influenciam uma decisão. Em 2015, Steve Lohr no seu livro Data-ism debruçou-se sobre as transformações que o Big Data estava operando, esta operando na sociedade. E utilizou o termo para descrever justamente essa grande revolução dos dados. Em 2016 o termo foi utilizado pelo autor e historiador Yuval Noah Harari. Ele é autor de alguns livros bem famosos best sellers como Sapiens, Uma Breve História da Humanidade ou Homo Deus, Uma Breve História do Amanhã e o 21 Lições para o século XXI . Esse autor fala que, em sua forma mais extrema, os proponentes da visão de mundo dataísta percebem o universo inteiro como um fluxo de dados, veem os organismos como um pouco mais do que algoritmos bioquímicos e acreditam que a vocação cósmica da humanidade é criar um sistema de processamento de dados abrangente e se fundir nele. Mas eu me pergunto será que é isso mesmo que a gente quer? E o que isso realmente significa? Quais os impactos? O autor ainda destaca que estamos nos tornando minúsculos chips dentro desse sistema gigante que ninguém realmente consegue compreender. Se antes os sentimentos e emoções eram um método para as nossas tomadas de decisão, com essa visão existe a possibilidade de um sistema externo tomar as decisões mais importantes para mim. E será que um sistema externo sabe mais de mim do que eu mesma? Ou sabe o que é mais importante para mim? Por exemplo, digamos que eu estou vivendo uma situação de estresse e tenho acoplada a mim um dispositivo, um monitor que controla os meus níveis de cortisol, adrenalina e em situações que essas substâncias sobem no meu corpo, ele libera na minha corrente sanguínea antídotos, antídotos para me manter calmo. Até aí, tudo bem perfeito. Só que, de repente, eu estou em uma situação a ponto de sofrer um acidente. E é justamente a adrenalina que me ajuda a ter uma resposta rápida em momentos de risco. Então, nesse caso, eu preciso estar estressada e com muita adrenalina para conseguir tomar uma decisão e sair dessa situação rapidamente, eu não posso que o sistema diminua minha adrenalina. É um exemplo bem grotesco, mas é só para ajudar a gente a pensar se a gente quer toda essa situação, bom. Outra questão a se pensar é que algoritmos e artefatos, as coisas da Internet das coisas são feitos por pessoas. E se não chamarmos a questão da ética e da moralidade, podemos ter algoritmos tendenciosos e coisas com falhas. Aí, nesse sentido, alguns autores defendem que, para fomentar a integração dos algoritmos em processos sociais e econômicos, são necessárias ferramentas de governança de algoritmos. E a governança dos algoritmos, por sua vez, pode variar desde o ponto de vista estritamente legal e regulatório até o ponto de vista técnico. Entre os pontos de regulação estão a questão da transparência e da responsabilidade. A questão da transparência significa que a gente tem que garantir que o algoritmo não seja uma grande caixa preta, que ele possa ser auditado. Isso é importante, inclusive, para quem compra ou usa a tecnologia. Como é que eu vou confiar numa indicação de um algoritmo se eu não tenho a mínima ideia de onde ele pegou esses dados e como que ele está tomando essas decisões na questão da responsabilidade, temos um sistema muito complexo e precisamos inclusive compreender o que são os artefatos técnicos e as coisas e suas características, para daí começar a mapear se as coisas possuem um caráter moral. Esse é um ponto muito importante, controverso. Quem seria responsabilizado por consequências decorrentes da ação de uma coisa criada pelo homem o humano ou a coisa? Se a Alexa responder a algo errado, quem é o responsável por isso? Em um acidente com os carros autônomos e os carros automáticos, quem é o responsável? Questões como a responsabilidade dos desenvolvedores e a existência de moralidade em atores não humanos nas coisas precisam de uma resposta ou pelo menos, de uma reflexão que contribua com o debate na esfera pública. Até agora, uma das teorias que mais contribuiu para essa discussão foi a Teoria Ator-Rede que foi proposta pelo Bruno Latour e outros pesquisadores que considera tanto os atores humanos como os não humanos. E isso é um avanço nessa discussão toda de responsabilidade, pois ela descarta essa diferença, essa divisão binária formal entre humanos e não humanos. Diante desse contexto, do ponto de vista legal e regulatório, atribuir status diferenciados aos artefatos técnicos de acordo com as suas capacidades de ação e influência, é justificável e deve ser dotada de um status moral e de responsabilidade diferenciados. É preciso, então, discutir e distinguir a influência e importância de cada coisa dentro da rede e, sobretudo, na esfera pública. E, a partir daí, pensar o que pode ser feito no cenário da Internet das Coisas. Sem contar que nós precisamos pensar na moralidade da coisa. A partir do momento que o objeto ou sistema é inteligente, ele precisa também compreender a questão moral. Se não, nós teremos outros fracassos, como por exemplo, o robô Tay, da Microsoft, em 2016, que era um programa de inteligência artificial dotado de uma capacidade de aprendizagem, que que ele fazia? O robô moldou a sua visão de mundo a partir de interações online no Twitter com outras pessoas, e daí ele ia publicar no Twitter as próprias expressões a partir dela. Acontece que em menos de um dia, o robô já estava gerando comentários totalmente inapropriados, incluindo publicações racistas, sexistas e antissemitas. Difícil né! Como ele aprendeu com as pessoas eu acho que também vale a pena a gente dar uma trabalhada na questão da inteligência humana e na questão da empatia e tolerância, mas essa é uma outra história e fica para depois. Voltando outro caso semelhante aconteceu com o Google Photos, que aprendeu com os usuários a marcar fotos. Os resultados também no início, foram bem desagradáveis. Eita! Particularmente, o uso de ferramentas de inteligência artificial que interagem por meio das mídias sociais exige que a gente reflita sobre os requisitos éticos que devem acompanhar o desenvolvimento desse tipo de tecnologia. Isso porque esses mecanismos também atuam como agentes na sociedade e acabam influenciando o ambiente ao seu redor. Mesmo sendo elementos não humanos. Não se trata, portanto, de pensar apenas no uso e no reparo das novas tecnologias, mas principalmente na orientação ética adequada para o seu uso em desenvolvimento . Ainda mais agora que estamos dando aos sistemas mais formas de sentir e de monitorar o ambiente externo e também de interagir com esse ambiente externo. Por exemplo, como seria a tomada de decisão de um automóvel inteligente diante de uma situação parecida com o dilema filosófico do trem? Não sei se você conhece esse dilema, mas é assim o trem está correndo pelos trilhos e está fora de controle. Se ele continuar no seu curso e não for desviado, ele vai passar por cima de cinco pessoas que foram amarradas aos trilhos. Você tem a chance de desviá lo para uma outra pista, simplesmente puxando uma alavanca. Só que se você fizer isso, você vai matar um homem que está por acaso parado nessa pista. O que fazer? Essa é uma situação complexa e que muitos de nós humanos, temos dificuldade para decidir. Mas e agora? Que regras a gente passa para essa máquina, para ela tomar uma decisão? Quem será esse homem? E se esse homem foi importante? E se ele é o cara que está prestes a descobrir a cura de uma doença que vai beneficiar toda a humanidade. Um outro exemplo de situação é digamos que eu estou num carro automático, controlado por tecnologia, numa situação onde se eu for por um lado eu sofro um acidente e se eu for para o outro lado, eu atropela uma pessoa. Mas fico bem. E agora, José? É difícil? Bom. Por hora, vamos ficando por aqui. Eu já viajei bastante e acho que agora a gente já tem muito o que pensar sobre o futuro. E já sabemos que, além de se preocupar com as coisas, com as bases e regras morais e éticas para a humanidade, nós também vamos ter que pensar nas regras para as coisas inteligentes, principalmente pensar numa base ética para o desenvolvimento das coisas. Mas, enquanto a gente não tem essas respostas, fique ligado, porque no próximo módulo nós vamos ver como a Internet das Coisas está sendo aplicada em diversas áreas. Nós vamos começar falando dos dispositivos vestíveis. Um super beijo e até lá!
